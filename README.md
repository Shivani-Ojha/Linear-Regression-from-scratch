Linear Regression from Scratch: A Comparison with Scikit-learn

#### ------ Project Overview ----- ####
This project demonstrates the implementation of simple linear regression to predict salary based on years of experience. The core of this project is a dual approach:
A quick solution using the powerful LinearRegression model from the scikit-learn library.
A from-scratch implementation of linear regression using the Gradient Descent optimization algorithm.
This serves as a great learning exercise to understand the underlying mechanics of how a machine learning model learns and optimizes its parameters.

#### ------ Dataset ------ ####
The dataset used in this project is a simple CSV file named Salary_Data.csv containing two columns:
YearsExperience: The number of years an individual has worked.
Salary: The corresponding salary.
The data exhibits a strong positive linear relationship, making it an excellent candidate for a simple linear regression model.

#### ------ Methodology ------ ####
1. Scikit-learn Implementation
The scikit-learn portion of the code follows a standard machine learning workflow:
The data is loaded and split into training (80%) and testing (20%) sets.
A LinearRegression model is initialized and trained on the training data.
The model's performance is evaluated using R-squared and Mean Squared Error (MSE) on the test data.

2. Gradient Descent Implementation

To provide a deeper understanding, the project manually implements the core logic of linear regression:
Loss Function: The Mean Squared Error (MSE) is used to measure the difference between the model's predictions and the actual values.
Gradients: The gradients of the loss function with respect to the slope (m) and intercept (b) are calculated. These gradients indicate the direction of the steepest ascent of the loss function.
Parameter Update: The m and b parameters are iteratively updated by moving in the opposite direction of the gradient, scaled by a learning_rate. This process is repeated for a set number of epochs to minimize the loss.

#### ------ Visualizations ------ ####

The script generates two key plots:
A scatter plot of the raw data, showing the relationship between years of experience and salary.
A final plot comparing the regression lines generated by both the scikit-learn model and the from-scratch Gradient Descent model, superimposed on the original data points. This visually confirms that both methods arrive at a very similar "best fit" line.

#### ------ Requirements ------ ####

Ensure you have the following Python libraries installed. You can install them using pip:
pip install pandas numpy matplotlib scikit-learn

#### ------ Execution ------ ####

To run the script, save the code as a Python file (e.g., linear_regression.py) and execute it from your terminal:
python linear_regression.py
#### ------ Potential Enhancements ------####
This project can be extended in several ways to further your learning:
Try implementing different optimization algorithms like Stochastic Gradient Descent (SGD) or Adam.
Experiment with different learning rates and epoch values to see how they affect the model's convergence.
Extend the model to handle multiple features (Multiple Linear Regression).
Add a feature to save the trained model for future use.

Author: Shivani Ojha
